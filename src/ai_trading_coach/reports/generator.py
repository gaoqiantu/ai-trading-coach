from __future__ import annotations

from collections import Counter, defaultdict
from dataclasses import dataclass
from datetime import date, datetime, timedelta
from decimal import Decimal
import json
from typing import Iterable

try:
    from zoneinfo import ZoneInfo
except Exception:  # pragma: no cover
    ZoneInfo = None  # type: ignore

from ai_trading_coach.analysis.events import EventLevel, TradeEvent, detect_events_for_lifecycles
from ai_trading_coach.domain.trade_lifecycle import TradeLifecycle


@dataclass(frozen=True)
class DisciplineScore:
    score: int
    breakdown: dict[str, int]


def compute_discipline_score(events: Iterable[TradeEvent]) -> DisciplineScore:
    """
    Deterministic scoring:
    - Start 100
    - P0: -20 each
    - P1: -8 each
    - P2: 0 (informational)
    - Floor at 0
    """
    score = 100
    breakdown: dict[str, int] = {"base": 100, "P0": 0, "P1": 0, "P2": 0}
    for e in events:
        if e.level == EventLevel.P0:
            score -= 20
            breakdown["P0"] -= 20
        elif e.level == EventLevel.P1:
            score -= 8
            breakdown["P1"] -= 8
        else:
            breakdown["P2"] += 0
    if score < 0:
        score = 0
    return DisciplineScore(score=score, breakdown=breakdown)

def _penalty_reason_lines(events: list[TradeEvent]) -> list[str]:
    """
    Only keep what changes tomorrow's behavior:
    - reason (event name)
    - count
    - penalty magnitude
    """
    points = {EventLevel.P0: 20, EventLevel.P1: 8}
    agg: dict[tuple[EventLevel, str], int] = {}
    for e in events:
        if e.level not in (EventLevel.P0, EventLevel.P1):
            continue
        key = (e.level, e.name_zh)
        agg[key] = agg.get(key, 0) + 1

    items: list[tuple[int, EventLevel, str, int]] = []
    for (lvl, name), cnt in agg.items():
        penalty = cnt * points[lvl]
        items.append((penalty, lvl, name, cnt))
    items.sort(key=lambda x: (-x[0], 0 if x[1] == EventLevel.P0 else 1, x[2]))

    out: list[str] = []
    for penalty, lvl, name, cnt in items:
        out.append(f"- {lvl.value} {name} x{cnt}ï¼ˆ-{penalty}ï¼‰")
    return out


def _penalty_reason_summary(events: list[TradeEvent], *, top_n: int = 2) -> str:
    """
    One-line penalty summary. No engineer-y breakdown.
    """
    lines = _penalty_reason_lines(events)
    if not lines:
        return "æ— ï¼ˆæ²¡è¯æ®å°±ä¸æ‰£ï¼‰"
    cleaned = [x[2:] if x.startswith("- ") else x for x in lines[:top_n]]
    if len(lines) > top_n:
        cleaned.append(f"â€¦å¦æœ‰{len(lines)-top_n}é¡¹")
    return "ï¼›".join(cleaned)


def _to_tz(dt: datetime | None, tz_name: str) -> datetime | None:
    if not dt:
        return None
    if ZoneInfo is None:
        return dt
    try:
        return dt.astimezone(ZoneInfo(tz_name))
    except Exception:
        return dt


def _fmt_hhmm(dt: datetime | None, *, tz_name: str = "America/New_York") -> str:
    dt2 = _to_tz(dt, tz_name)
    if not dt2:
        return "--:--"
    try:
        return dt2.strftime("%H:%M")
    except Exception:
        return "--:--"


def summarize_risk_signals(events: Iterable[TradeEvent]) -> list[str]:
    """
    Deterministic summary strings (Chinese), derived from event types.
    """
    counts = Counter([e.event_type.value for e in events if e.level in (EventLevel.P0, EventLevel.P1)])
    signals: list[str] = []
    for k, v in counts.most_common():
        signals.append(f"{k} x{v}")
    return signals


def _events_stats(events: list[TradeEvent]) -> dict[str, int]:
    c = Counter([e.level.value for e in events])
    return {"P0": c.get("P0", 0), "P1": c.get("P1", 0), "P2": c.get("P2", 0), "total": len(events)}

def _format_evidence_brief(e: TradeEvent) -> str:
    """
    Short, accountable evidence string (Chinese). Always derived from event.evidence fields.
    """
    ev = e.evidence or {}
    t = e.event_type.value

    def _short_ts(ts: str | None) -> str:
        if not ts:
            return "NA"
        try:
            d, tpart = ts.split("T", 1)
            return f"{d[5:10]} {tpart[0:5]}"
        except Exception:
            return ts[:16]

    if t == "night_trading_us_eastern":
        return f"ç¾ä¸œå¼€ä»“ï¼š{_short_ts(ev.get('entry_ts_us_eastern'))}\nè§„åˆ™ï¼šå¤œç›˜ 22:00-06:00 ç¦å¼€æ–°ä»“"
    if t == "high_leverage_used":
        return f"effective_leverage={ev.get('effective_leverage')}ï½œé˜ˆå€¼={ev.get('threshold')}ï¼ˆåŸºå‡†={ev.get('base_balance_source')}ï¼‰"
    if t == "big_loss_pct_equity":
        return f"loss%={ev.get('loss_pct_of_base_balance')}ï½œé˜ˆå€¼%={ev.get('threshold_pct')}ï¼ˆåŸºå‡†={ev.get('base_balance_source')}ï¼‰"
    if t == "stop_loss_triggered":
        tf = ev.get("trigger_fill") or {}
        return f"è®¡åˆ’æ­¢æŸ={ev.get('planned_stop_loss')}ï½œè§¦å‘æˆäº¤ price={tf.get('price')} amount={tf.get('amount')}"
    if t == "consecutive_losses":
        return f"n={ev.get('n')}ï¼ˆæœ€è¿‘Nç¬”éƒ½äºï¼‰"

    # Default: dump compact json (still structured evidence)
    return "è¯æ®ï¼šè§äº‹ä»¶ evidenceï¼ˆæœ¬æŠ¥å‘Šå·²åšç²¾ç®€å±•ç¤ºï¼‰"


def _viper_comments(lifecycles: list[TradeLifecycle], events: list[TradeEvent]) -> list[str]:
    """
    Cold coach, no fluff. Each line must reference concrete metrics or event evidence.
    """
    by_lc: dict[str, list[TradeEvent]] = defaultdict(list)
    for e in events:
        if e.level in (EventLevel.P0, EventLevel.P1):
            by_lc[e.lifecycle_id].append(e)

    lines: list[str] = []
    # Sort by worst first: P0 > P1, then by timestamp
    all_lcs = sorted(
        lifecycles,
        key=lambda lc: (
            -sum(1 for e in by_lc.get(lc.lifecycle_id, []) if e.level == EventLevel.P0),
            -sum(1 for e in by_lc.get(lc.lifecycle_id, []) if e.level == EventLevel.P1),
            lc.metrics.entry_ts or datetime.min,
        ),
    )

    def pick_variant(key: str, variants: list[str]) -> str:
        idx = abs(hash(key)) % len(variants)
        return variants[idx]

    for lc in all_lcs:
        lc.recompute()
        pnl = lc.metrics.realized_pnl_usdt
        evs = by_lc.get(lc.lifecycle_id, [])
        sym = lc.symbol
        side = lc.position_side.value

        # One line per trade, short, blunt, actionable.
        if pnl is None:
            variants = [
                "è¿˜æ²¡ç»“ç®—å°±åˆ«è®²å¤ç›˜ï¼šå…ˆæŠŠè¿™ç¬”å¹³æ‰ï¼Œæˆ–è€…æ‰¿è®¤ä½ åœ¨èµŒã€‚",
                "pnl ä¸ºç©º=ä½ æ²¡å…³è´¦ã€‚æ˜å¤©ç¬¬ä¸€ä»¶äº‹ï¼šæŠŠâ€œä½•æ—¶ç®—ç»“æŸâ€å†™æˆè§„åˆ™ã€‚",
                "ä½ è¿è¾“èµ¢éƒ½æ²¡è½åˆ°æ•°æ®å£å¾„ï¼Œè¿˜è°ˆä»€ä¹ˆçºªå¾‹ï¼Ÿå…ˆè¡¥é½ç»“ç®—å£å¾„ã€‚",
            ]
            idx = abs(hash(lc.lifecycle_id)) % len(variants)
            lines.append(f"- ğŸ§¾ **{sym} {side}**ï¼š{variants[idx]}")
            continue

        if any(e.event_type.value == "night_trading_us_eastern" for e in evs):
            variants = [
                "å¤œç›˜å¼€ä»“å°±æ˜¯è‡ªæ‰¾éº»çƒ¦ï¼š22:00-06:00 ç¦å¼€æ–°ä»“ï¼Œå†™è¿›ç¡¬çº¦æŸã€‚",
                "å¤œç›˜å¼€ä»“=è‡ªæ›å¼±ç‚¹ã€‚æ”¹æ³•ä¸å¤æ‚ï¼šå¤œç›˜ä¸ä¸‹æ‰‹ã€‚",
                "åˆ«æŠŠå¤œç›˜å½“è®­ç»ƒåœºï¼Œä½ æ˜¯åœ¨ç»ƒæ€ä¹ˆäºé’±ï¼šå¤œç›˜ç¦å¼€æ–°ä»“ã€‚",
            ]
            lines.append(f"- ğŸŒ™ **{sym} {side}**ï¼š{pick_variant(lc.lifecycle_id, variants)}")
            continue

        if pnl < 0:
            variants = [
                "äºæŸä¸æ˜¯å§”å±ˆï¼Œæ˜¯è´¦å•ã€‚æ”¹æ³•ï¼šè¿›åœºå‰å†™æ­»é€€å‡ºæ¡ä»¶ï¼ˆæ­¢æŸ/è¶…æ—¶/æ’¤é€€ï¼‰ã€‚",
                "è¾“é’±ä¸æ˜¯é—®é¢˜ï¼Œæ²¡è§„åˆ™æ‰æ˜¯ã€‚æ”¹æ³•ï¼šå•ç¬”æœ€å¤§äºæŸé˜ˆå€¼å›ºå®šï¼Œè§¦å‘å°±åœã€‚",
                "è¿™ç¬”äºæŸåœ¨æé†’ä½ ï¼šå…ˆæ§é£é™©ï¼Œå†è°ˆæ”¶ç›Šã€‚æ”¹æ³•ï¼šæŠŠæ æ†/ä»“ä½ä¸Šé™å†™æ­»ã€‚",
            ]
            lines.append(f"- ğŸ”» **{sym} {side}**ï¼š{pick_variant(lc.lifecycle_id, variants)}ï¼ˆpnl={pnl}ï¼‰")
            continue

        variants = [
            "ç›ˆåˆ©ä¸ç­‰äºçºªå¾‹ã€‚æ”¹æ³•ï¼šæŠŠä»Šå¤©æ²¡å‡ºäº‹çš„æ­¥éª¤å†™æˆæ£€æŸ¥æ¸…å•ï¼Œä¸‹æ¬¡ç…§æŠ„ã€‚",
            "è¿™ç¬”èµšåˆ°çš„æ˜¯ç»“æœï¼Œä¸æ˜¯èƒ½åŠ›ã€‚æ”¹æ³•ï¼šæŠŠå¯å¤åˆ¶åŠ¨ä½œå›ºåŒ–ï¼Œåˆ«é è¿æ°”ã€‚",
            "åˆ«åº†ç¥ï¼Œå†™æ€»ç»“ã€‚æ”¹æ³•ï¼šæ˜ç¡®å“ªä¸€æ­¥æ˜¯çºªå¾‹è´¡çŒ®çš„ï¼Œä¸‹ä¸€æ¬¡åªé‡å¤é‚£ä¸€æ­¥ã€‚",
        ]
        lines.append(f"- ğŸŸ¢ **{sym} {side}**ï¼š{pick_variant(lc.lifecycle_id, variants)}ï¼ˆpnl={pnl}ï¼‰")

    return lines


def _fmt_hhmm(dt: datetime | None) -> str:
    # Display in US/Eastern by default (review timezone).
    dt2 = _to_tz(dt, "America/New_York")
    if not dt2:
        return "--:--"
    try:
        return dt2.strftime("%H:%M")
    except Exception:
        return "--:--"


def _fmt_price(x: Decimal | None) -> str:
    if x is None:
        return "NA"
    s = format(x, "f")
    if "." in s:
        s = s.rstrip("0").rstrip(".")
    if len(s) > 14:
        return f"{x:.6g}"
    return s


def _fmt_amt(x: Decimal | None) -> str:
    if x is None:
        return "NA"
    s = format(x, "f")
    if "." in s:
        s = s.rstrip("0").rstrip(".")
    if len(s) > 14:
        return f"{x:.6g}"
    return s


def _top_costly_mistakes(lifecycles: list[TradeLifecycle], top_n: int = 5) -> list[dict[str, str]]:
    """
    "Most expensive mistakes": rank by realized loss magnitude (USDT).
    """
    rows: list[dict[str, str]] = []
    losers = []
    for lc in lifecycles:
        lc.recompute()
        pnl = lc.metrics.realized_pnl_usdt
        if pnl is None:
            continue
        if pnl < 0:
            losers.append((abs(pnl), lc))
    losers.sort(key=lambda x: x[0], reverse=True)
    for loss_abs, lc in losers[:top_n]:
        rows.append(
            {
                "lifecycle_id": lc.lifecycle_id,
                "symbol": lc.symbol,
                "side": lc.position_side.value,
                "loss_usdt": str(loss_abs),
                "entry_ts": (lc.metrics.entry_ts.isoformat() if lc.metrics.entry_ts else ""),
                "exit_ts": (lc.metrics.exit_ts.isoformat() if lc.metrics.exit_ts else ""),
            }
        )
    return rows


def _behavior_patterns(events: list[TradeEvent]) -> dict[str, int]:
    """
    Simple deterministic pattern counts by event_type (P0+P1).
    """
    c = Counter([e.event_type.value for e in events if e.level in (EventLevel.P0, EventLevel.P1)])
    return dict(c)


def _hard_constraints_suggestions(pattern_counts: dict[str, int]) -> list[str]:
    """
    Hard constraints (Chinese). Not price prediction, not trade advice.
    Triggered deterministically based on observed patterns.
    """
    out: list[str] = []
    if pattern_counts.get("night_trading_us_eastern", 0) > 0:
        out.append("ç¡¬çº¦æŸï¼šä»ç°åœ¨èµ·ï¼Œç¦æ­¢ç¾ä¸œ22:00-06:00å¼€æ–°ä»“ï¼ˆä½ å·²ç»å¤œç›˜å¼€ä»“äº†ï¼‰ã€‚")
    if pattern_counts.get("high_leverage_used", 0) > 0:
        out.append("ç¡¬çº¦æŸï¼šæœ‰æ•ˆæ æ†ä¸Šé™=10xï¼ˆä½ å·²ç»ç”¨è¿‡é«˜æ æ†äº†ï¼‰ã€‚")
    if pattern_counts.get("big_loss_pct_equity", 0) > 0:
        out.append("ç¡¬çº¦æŸï¼šå•ç¬”æœ€å¤§å…è®¸äºæŸ=å¯ç”¨ä¿è¯é‡‘çš„3%ï¼ˆä½ å·²ç»å‡ºç°å•ç¬”å¤§äºäº†ï¼‰ã€‚")
    if pattern_counts.get("consecutive_losses", 0) > 0:
        out.append("ç¡¬çº¦æŸï¼šè¿ç»­äºæŸè§¦å‘åå†·é™æœŸ=24å°æ—¶ä¸äº¤æ˜“ï¼ˆä½ å·²ç»è¿ç»­äºæŸäº†ï¼‰ã€‚")
    return out


def generate_daily_report_md(*, period_start: datetime, period_end: datetime, lifecycles: list[TradeLifecycle]) -> str:
    events = detect_events_for_lifecycles(lifecycles)
    stats = _events_stats(events)
    score = compute_discipline_score(events)
    p0p1 = [e for e in events if e.level in (EventLevel.P0, EventLevel.P1)]
    p0p1.sort(key=lambda e: (0 if e.level == EventLevel.P0 else 1, e.occurred_at))
    patterns = _behavior_patterns(p0p1)
    hard_constraints = _hard_constraints_suggestions(patterns)
    penalty_summary = _penalty_reason_summary(events)

    lines: list[str] = []
    lines.append(f"## ğŸ§¾ æ¯æ—¥å¤ç›˜ï¼ˆç¾ä¸œï¼‰ {period_start.date().isoformat()}")
    lines.append("")

    # â‘  ä»Šæ—¥è£å†³ï¼ˆå¼ºåˆ¶é˜…è¯» 1-3 è¡Œï¼‰
    lines.append("### â‘  ä»Šæ—¥è£å†³ï¼ˆå¼ºåˆ¶é˜…è¯»ï¼‰")
    lines.append(f"- ä»Šæ—¥è£å†³ï¼šP0={stats['P0']}ï¼ŒP1={stats['P1']}ã€‚åˆ«è§£é‡Šã€‚")
    if hard_constraints:
        # keep only one: the next-day action
        lines.append(f"- æ˜æ—¥åªæ”¹ä¸€ä»¶äº‹ï¼š{hard_constraints[0]}")
    else:
        lines.append("- æ˜æ—¥åªæ”¹ä¸€ä»¶äº‹ï¼šæ— ï¼ˆä»Šå¤©æ²¡è¯æ®è§¦å‘ç¡¬çº¦æŸï¼‰")
    lines.append("")

    # â‘¡ çºªå¾‹åˆ† & æ‰£åˆ†åŸå› ï¼ˆåªè®²åŸå› +å¹…åº¦ï¼›åˆ æ‰å·¥ç¨‹ç»†èŠ‚ï¼‰
    lines.append("### â‘¡ çºªå¾‹åˆ† & æ‰£åˆ†åŸå› ")
    lines.append(f"- çºªå¾‹åˆ†ï¼š**{score.score}/100**")
    lines.append(f"- æ‰£åˆ†ï¼š{penalty_summary}")
    lines.append("")

    # â‘¢ è¯æ®ä¸è¿½è´£ï¼ˆé™„ä»¶å¯æŠ˜å ï¼Œå±•ç¤ºæç®€ï¼‰
    lines.append("### â‘¢ è¯æ®ä¸è¿½è´£ï¼ˆéœ€è¦æ—¶å†çœ‹ï¼‰")
    if p0p1:
        # keep only the minimum: up to 3 events
        for e in p0p1[:3]:
            lines.append(f"- {e.level.value} {e.name_zh}ï½œ{e.symbol}")
            for ln in _format_evidence_brief(e).splitlines()[:2]:
                lines.append(f"  - {ln}")
        if len(p0p1) > 3:
            lines.append(f"- â€¦ å…¶ä½™ {len(p0p1) - 3} æ¡äº‹ä»¶ç•¥")
    else:
        lines.append("- æ— P0/P1ï¼ˆæ²¡è¯æ®å°±ä¸åˆ¤ï¼‰")
    lines.append("")

    # äº¤æ˜“åˆ—è¡¨ï¼ˆæç®€ï¼šå¼€å¹³æ—¶é—´ç®€å†™ + å¼€å¹³ä»· + é‡ + ç›ˆäº%ä¿è¯é‡‘ï¼‰
    lines.append("### ğŸ“’ ä»Šæ—¥äº¤æ˜“ï¼ˆ30ç§’æ‰«å®Œï¼‰")
    if not lifecycles:
        lines.append("- æ— ")
    else:
        shown = 0
        # Closed first, then open; stable sort by entry time.
        lifecycles_sorted = sorted(
            lifecycles,
            key=lambda lc: (0 if lc.status == "closed" else 1, lc.metrics.entry_ts or datetime.min),
        )
        for lc in lifecycles_sorted:
            if shown >= 8:
                break
            lc.recompute()
            entry_t = _fmt_hhmm(lc.metrics.entry_ts)
            exit_t = _fmt_hhmm(lc.metrics.exit_ts)
            entry_px = _fmt_price(lc.metrics.entry_avg_price)
            exit_px = _fmt_price(lc.metrics.exit_avg_price)
            qty = _fmt_amt(lc.metrics.max_abs_position_amount)
            pnl = lc.metrics.realized_pnl_usdt
            pnl_pct = lc.metrics.realized_pnl_pct_of_available_margin
            status = "âœ…å·²å¹³" if lc.status == "closed" else "ğŸ•—æœªå¹³"
            pnl_str = "æœªç»“ç®—" if pnl is None else f"{pnl:.2f}U"
            pct_str = "" if pnl_pct is None else f"ï¼ˆ{pnl_pct:.2f}%ä¿è¯é‡‘ï¼‰"
            # Open trades: hide exit time/price to reduce noise
            if lc.status != "closed":
                lines.append(f"- {status} {lc.symbol} {lc.position_side.value}ï½œ{entry_t}@{entry_px}ï½œé‡â‰ˆ{qty}ï½œ{pnl_str}")
            else:
                lines.append(f"- {status} {lc.symbol} {lc.position_side.value}ï½œ{entry_t}@{entry_px}â†’{exit_t}@{exit_px}ï½œé‡â‰ˆ{qty}ï½œ{pnl_str}{pct_str}")
            shown += 1
        if len(lifecycles) > shown:
            lines.append(f"- â€¦ å…¶ä½™ {len(lifecycles) - shown} ç¬”ç•¥")
    lines.append("")

    # Coach: only 3 short lines max
    lines.append("### ğŸ æ•™ç»ƒï¼ˆ1åˆ†é’ŸçŸ¥é“æ˜å¤©æ€ä¹ˆæ”¹ï¼‰")
    for c in _viper_comments(lifecycles, p0p1)[:3]:
        lines.append(c)
    lines.append("")
    lines.append("- å…¨é‡è¯æ®åœ¨æœ¬åœ° SQLiteï¼š`lifecycles.data_json`ï¼ˆfillså« trade_id/order_idï¼‰")
    return "\n".join(lines)


def generate_periodic_report_md(
    *,
    title_zh: str,
    period_start: datetime,
    period_end: datetime,
    lifecycles: list[TradeLifecycle],
) -> str:
    """
    Weekly / Monthly report template.
    """
    events = detect_events_for_lifecycles(lifecycles)
    stats = _events_stats(events)
    patterns = _behavior_patterns(events)
    top5 = _top_costly_mistakes(lifecycles, top_n=5)
    hard_constraints = _hard_constraints_suggestions(patterns)

    lines: list[str] = []
    lines.append(f"## {title_zh}ï¼ˆç¾ä¸œï¼‰")
    lines.append(f"- å‘¨æœŸï¼š{period_start.isoformat()} ~ {period_end.isoformat()}")
    lines.append("")
    lines.append("### äº‹ä»¶ç»Ÿè®¡")
    lines.append(f"- P0={stats['P0']} / P1={stats['P1']} / P2={stats['P2']}ï¼ˆå…± {stats['total']}ï¼‰")
    lines.append("")
    lines.append("### è¡Œä¸ºæ¨¡å¼ç»Ÿè®¡ï¼ˆP0/P1ï¼Œåªç®—è¯æ®ï¼‰")
    if patterns:
        for k, v in sorted(patterns.items(), key=lambda kv: kv[1], reverse=True):
            lines.append(f"- {k}: {v}")
    else:
        lines.append("- æ— ")
    lines.append("")
    lines.append("### æœ€æ˜‚è´µçš„é”™è¯¯ Top5ï¼ˆæŒ‰äºæŸé¢ï¼‰")
    if top5:
        for r in top5:
            lines.append(
                f"- {r['lifecycle_id']} | {r['symbol']} | {r['side']} | loss={r['loss_usdt']} | "
                f"{r['entry_ts']} -> {r['exit_ts']}"
            )
    else:
        lines.append("- æ— ï¼ˆæˆ–ç¼ºå°‘pnlï¼‰")
    lines.append("")
    lines.append("### çºªå¾‹è¶‹åŠ¿å˜åŒ–")
    lines.append("- ï¼ˆé¢„ç•™ï¼‰å°†æŒ‰å‘¨/æœˆå¯¹ P0/P1 çš„é¢‘æ¬¡ä¸çºªå¾‹è¯„åˆ†è¶‹åŠ¿åšå¯¹æ¯”å›¾/è¡¨ã€‚")
    lines.append("")
    lines.append("### ä¸‹ä¸€ä¸ªå‘¨æœŸç¡¬çº¦æŸï¼ˆå‘½ä»¤ï¼Œä¸æ˜¯å»ºè®®ï¼‰")
    if hard_constraints:
        for s in hard_constraints:
            lines.append(f"- {s}")
    else:
        lines.append("- æ— ï¼ˆç›®å‰æ²¡æœ‰è¶³å¤Ÿè¯æ®è§¦å‘ç¡¬çº¦æŸï¼‰")
    lines.append("")
    lines.append("### è¯æ®ç´¢å¼•")
    lines.append("- æ‰€æœ‰ç»“è®ºå¿…é¡»èƒ½åœ¨äº‹ä»¶ evidence ä¸ lifecycle çš„ fills ä¸­æ‰¾åˆ°å¯¹åº”è¯æ®ã€‚")
    return "\n".join(lines)


